import os
import pandas as pd

### This script takes peptides.csv, protein.csv, and taxonomy.csv as input.
### The higher-level datasets are generated by removing the lower-level ones.
### The lower-level datasets are also generated.
### The .fasta files are generated.

# Function to process the taxonomy DataFrame
def process_taxonomy_data(df_taxonomy, combined):
    def create_lists_from_taxonomy(df):
        lists_dict = {}
        for index, row in df.iterrows():
            name = row['ScientificName']
            ids = row['IDs']
            lists_dict[name] = list(set(int(i) for i in ids.split(',') if i != 'NA'))
        return lists_dict

    lists_dict = create_lists_from_taxonomy(df_taxonomy)
    scientific_names = df_taxonomy['ScientificName'].tolist()

    # Perform subtraction only between the highest level and the lowest level
    highest_level_name = scientific_names[0]
    lowest_level_name = scientific_names[-1]

    # Print lists before subtraction
    print(f"\nIDs at the highest level ({highest_level_name}): {lists_dict[highest_level_name]}")
    print(f"Number of IDs at the highest level: {len(lists_dict[highest_level_name])}")

    print(f"\nIDs at the lowest level ({lowest_level_name}): {lists_dict[lowest_level_name]}")
    print(f"Number of IDs at the lowest level: {len(lists_dict[lowest_level_name])}")

    # Perform subtraction
    highest_minus_lowest = list(set(lists_dict[highest_level_name]) - set(lists_dict[lowest_level_name]))

    # Print the result of the subtraction
    print(f"\nSubtraction result ({highest_level_name} minus {lowest_level_name}): {highest_minus_lowest}")
    print(f"Number of IDs after subtraction: {len(highest_minus_lowest)}")

    # List IDs that are in both lists
    ids_comuns = set(lists_dict[highest_level_name]).intersection(lists_dict[lowest_level_name])

    # Check if the subtraction was correct
    if set(highest_minus_lowest).intersection(lists_dict[lowest_level_name]):
        print("Error: The subtraction contains IDs that should have been removed.")
    else:
        print("Correct subtraction.")

    # Create the resulting DataFrames
    highest_level_df = combined[combined['txid'].isin(highest_minus_lowest)].copy()
    highest_level_df['Class'] = highest_level_df['Class'].apply(lambda x: 0 if x == -1 else x)

    lowest_level_df = combined[combined['txid'].isin(lists_dict[lowest_level_name])].copy()
    lowest_level_df['Class'] = lowest_level_df['Class'].apply(lambda x: 0 if x == -1 else x)

    return highest_level_df, lowest_level_df

# Define the base path
base_path = "./input/organismos/taxons/"

# Check if the base directory exists
if not os.path.exists(base_path):
    raise FileNotFoundError(f"The base_path directory '{base_path}' was not found.")

# Initialize a dictionary to store DataFrames
organisms_data = {}

# Iterate through all folders in the base_path directory
for folder_name in os.listdir(base_path):
    folder_path = os.path.join(base_path, folder_name)

    if os.path.isdir(folder_path):
        print('####################################################')
        print(f"Processing organism: {folder_name}")
        csv_files = {
            'proteins': None,
            'peptides': None,
            'taxonomy': None,
            'merged': None,
            'highest_minus_lowest': None,
            'lowest_level': None
        }

        # Look for specific CSV files
        for file_name in os.listdir(folder_path):
            file_path = os.path.join(folder_path, file_name)

            if file_name.startswith("proteins_") and file_name.endswith(".csv"):
                csv_files['proteins'] = pd.read_csv(file_path)

            elif file_name.startswith("peptides_") and file_name.endswith(".csv"):
                csv_files['peptides'] = pd.read_csv(file_path)

            elif file_name.startswith("taxonomy_") and file_name.endswith(".csv"):
                csv_files['taxonomy'] = pd.read_csv(file_path)

        if csv_files['proteins'] is not None and csv_files['peptides'] is not None and csv_files['taxonomy'] is not None:
            print(f"Merging and processing taxonomy for: {folder_name}")
            merged_df = pd.merge(csv_files['peptides'], csv_files['proteins'], on="Info_protein_id")
            csv_files['merged'] = merged_df

            # Consistency check
            inconsistent_found = False
            for index, row in merged_df.iterrows():
                seq = row["Info_sequence"]
                start = row["Info_start_pos"] - 1
                end = row["Info_end_pos"]
                pepi = seq[start:end]
                if pepi != row["Info_peptide"]:
                    print(f"Inconsistency found in organism {folder_name} at line {index}")
                    inconsistent_found = True

            if not inconsistent_found:
                print(f"Consistent datasets for taxon {folder_name}")

            # Process the taxonomy DataFrame
            highest_minus_lowest_df, lowest_level_df = process_taxonomy_data(csv_files['taxonomy'], merged_df)
            csv_files['highest_minus_lowest'] = highest_minus_lowest_df
            csv_files['lowest_level'] = lowest_level_df

            organisms_data[folder_name] = csv_files
        else:
            print(f"Missing CSV files for organism: {folder_name}")

# Check if any organism was processed
if not organisms_data:
    raise ValueError("No organism was processed. Check the input data.")

def print_and_filter_dataframes(dataframes, selected_keys):
    filtered_dataframes = {}

    for key in selected_keys:
        if key in dataframes:
            df_dict = dataframes[key]
            highest_minus_lowest_df = df_dict.get('highest_minus_lowest')
            lowest_level_df = df_dict.get('lowest_level')

            if highest_minus_lowest_df is not None and 'Info_split_x' in highest_minus_lowest_df.columns:
                print(f"Info_split_x structure for highest_minus_lowest in {key}:")
                print(highest_minus_lowest_df['Info_split_x'].value_counts())

            if lowest_level_df is not None and 'Info_split_x' in lowest_level_df.columns:
                print(f"Info_split_x structure for lowest_level in {key}:")
                print(lowest_level_df['Info_split_x'].value_counts())

            # Add the key and corresponding dictionary to the new filtered dictionary
            filtered_dataframes[key] = df_dict
        else:
            print(f"Key {key} not found in dataframes.")

    return filtered_dataframes

selected_keys = ['Ctrachomatis', 'Human Gammaherpesvirus 4', 'Influenza A', 'Cdifficile', 'Filoviridae', 'Measles morbilivirus', 'Ovolvulus', 'Mononegavirales']
filtered_organisms_data = print_and_filter_dataframes(organisms_data, selected_keys)


def save_split_dataframes(filtered_dataframes, base_path):
    # Define the splits
    splits = {
        "fold1": ["split_01_20"],
        "fold2": ["split_02_20"],
        "fold3": ["split_03_20"],
        "fold4": ["split_04_20"],
        "fold5": ["split_05_20"]
    }

    # Iterate over the keys and folds to save the corresponding dataframes
    for key, df_dict in filtered_dataframes.items():
        highest_minus_lowest_dfs = []
        fold_sizes = {}
        lowest_level_df = df_dict.get('lowest_level')
        test_df = None

        # Identify the smallest fold
        for fold, split_list in splits.items():
            highest_minus_lowest_df = df_dict.get('highest_minus_lowest')
            if highest_minus_lowest_df is not None:
                fold_df = highest_minus_lowest_df[highest_minus_lowest_df["Info_split_x"].isin(split_list)]
                fold_sizes[fold] = len(fold_df)

        # Determine the smallest fold
        min_fold = min(fold_sizes, key=fold_sizes.get)

        for fold, split_list in splits.items():
            highest_minus_lowest_df = df_dict.get('highest_minus_lowest')
            if highest_minus_lowest_df is not None:
                fold_df = highest_minus_lowest_df[highest_minus_lowest_df["Info_split_x"].isin(split_list)]

                if not fold_df.empty:
                    # Save the individual fold
                    taxon_dir = os.path.join(base_path, key)
                    os.makedirs(taxon_dir, exist_ok=True)

                    file_path = os.path.join(taxon_dir, f"{fold}_highest_minus_lowest_{key}.csv")
                    fold_df.to_csv(file_path, index=False)
                    print(f"File saved at: {file_path}")

                    if fold == min_fold:
                        # Save the smallest fold as test
                        test_df = fold_df
                    else:
                        # Accumulate the other folds for training
                        highest_minus_lowest_dfs.append(fold_df)

            if lowest_level_df is not None:
                fold_df = lowest_level_df[lowest_level_df["Info_split_x"].isin(split_list)]
                if not fold_df.empty:
                    # Create the taxon folder if it doesn't exist
                    taxon_dir = os.path.join(base_path, key)
                    os.makedirs(taxon_dir, exist_ok=True)

                    file_path = os.path.join(taxon_dir, f"{fold}.csv")
                    fold_df.to_csv(file_path, index=False)
                    print(f"File saved at: {file_path}")

        # Concatenate the remaining folds to generate train_highest_minus_lowest.csv
        if highest_minus_lowest_dfs:
            train_df = pd.concat(highest_minus_lowest_dfs, ignore_index=True)
            taxon_dir = os.path.join(base_path, key)
            os.makedirs(taxon_dir, exist_ok=True)

            file_path = os.path.join(taxon_dir, "train_highest_minus_lowest.csv")
            train_df.to_csv(file_path, index=False)
            print(f"File saved at: {file_path}")

        # Save the test_highest_minus_lowest.csv
        if test_df is not None:
            taxon_dir = os.path.join(base_path, key)
            os.makedirs(taxon_dir, exist_ok=True)

            file_path = os.path.join(taxon_dir, "test_highest_minus_lowest.csv")
            test_df.to_csv(file_path, index=False)
            print(f"File saved at: {file_path}")

save_split_dataframes(filtered_organisms_data, base_path)


def concatenate_and_save_csv(csv_files, output_path):
    dataframes = []

    for csv_file in csv_files:
        df = pd.read_csv(csv_file)
        dataframes.append(df)

    concatenated_df = pd.concat(dataframes, ignore_index=True)

    for csv_file in csv_files:
        os.remove(csv_file)
        print(f"File {csv_file} deleted.")

    concatenated_df.to_csv(output_path, index=False)
    print(f"Concatenated file saved at: {output_path}")

csv_files = ['./input/organismos/taxons/Measles morbilivirus/fold1.csv', './input/organismos/taxons/Measles morbilivirus/fold2.csv', './input/organismos/taxons/Measles morbilivirus/fold3.csv', './input/organismos/taxons/Measles morbilivirus/fold4.csv']  # Replace with your files
output_path = './input/organismos/taxons/Measles morbilivirus/fold2.csv'
concatenate_and_save_csv(csv_files, output_path)

def write_fasta_from_csv(organism, fold_numbers):
    """
    Creates FASTA files from CSV files for a specific organism and a list of folds.

    Parameters:
        organism (str): Name of the organism.
        fold_numbers (list): List of fold numbers.
    """

    # Base path for output FASTA files
    base_output_path = f'{path_fasta}{organism}/'
    base_input_path = f'./input/organismos/taxons/{organism}/'

    # Ensure the directory exists, if not, create it
    os.makedirs(base_output_path, exist_ok=True)

    # Iterate over each fold number in the list
    for fold_number in fold_numbers:
        # Path for the output FASTA file
        output_fasta_path = f'{base_output_path}fold{fold_number}.fasta'

        # Path for the input CSV file
        fold_path = f"{base_input_path}/fold{fold_number}.csv"

        # Load the CSV file
        df = pd.read_csv(fold_path)

        # Create and write to the FASTA file
        with open(output_fasta_path, 'w') as fasta_file:
            for _, row in df.drop_duplicates(subset=['Info_protein_id']).iterrows():
                header = f">{row['Info_protein_id']}\n"
                sequence = f"{row['Info_sequence']}\n"
                fasta_file.write(header)
                fasta_file.write(sequence)

configurations = [
     {"organism": "Ctrachomatis", "fold_numbers": [1, 2, 3, 4, 5]},
     {"organism": "Human Gammaherpesvirus 4", "fold_numbers": [1, 2, 3, 4, 5]},
     {"organism": "Influenza A", "fold_numbers": [1, 2, 3, 4, 5]},
     {"organism": "Cdifficile", "fold_numbers": [1, 2, 3, 4, 5]},
     {"organism": "Filoviridae", "fold_numbers": [1, 2, 3, 4, 5]},
     {"organism": "Measles morbilivirus", "fold_numbers": [2, 5]},
     {"organism": "Ovolvulus", "fold_numbers": [1, 2, 3, 4, 5]},
     {"organism": "Mononegavirales", "fold_numbers": [1, 2, 3, 4, 5]},
]

path_fasta = "./fasta/folds/"
for config in configurations:
    write_fasta_from_csv(**config)
